---
header-includes:
   - \providecommand{\titletxt}{Tutorial - Spatial Analysis in R with Open Geodata}
   - \usepackage[skins]{tcolorbox}
   - \usepackage{float}
   - \usepackage{multicol}
   - \usepackage{graphicx}
   - \usepackage{lastpage}
   - \usepackage{fancyhdr}
   - \pagestyle{fancy}
   - \fancyhf{}
   - \lhead{Use of R in Official Statistics - uRos2018}
   - \rhead{6th international conference, The Hague, September 2018}
   - \usepackage[numbered]{bookmark}
   - \usepackage{hyperref}
   - \hypersetup{
     pdftitle={Tutorial - Spatial Analysis in R with Open Geodata - uRos2018},
     pdfauthor={Egge-Jan Pollé and Willy Tadema}
     }
   - \hypersetup{linkcolor = {blue}, urlcolor = {blue}}
   - \renewcommand{\footrulewidth}{0.4pt}
   - \fancyfoot{}
   - \fancyfoot[l]{\titletxt}
   - \fancyfoot[r]{Page \thepage\ of \pageref*{LastPage}}
   - \usepackage{fvextra}
   - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
   - \usepackage{xcolor}
   - \definecolor{grey}{rgb}{0.8,0.8,0.8}
   - \usepackage{enumitem}
   - \renewcommand{\figurename}{Figure}
output: 
  pdf_document:
    latex_engine: lualatex
mainfont: Calibri
urlcolor: blue
---


\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE,echo = TRUE)
```

\huge Tutorial - Spatial Analysis in R with Open Geodata

\normalsize

**Egge-Jan Pollé** - Tensing GIS Consultancy B.V.[^1]  
**Willy Tadema** - Provincie Groningen[^2]

Version 0.1.9 - August 1, 2018

\begin{multicols}{2}

\subsection{Introduction}


This is the manual for a tutorial session to be delivered on Wednesday 12 September 2018 at the 6\textsuperscript{th} International \href{https://www.aanmelder.nl/uros2018}{Conference on the Use of R in Official Statistics (uRos2018)} at the Dutch Office for National Statistics (\href{https://www.cbs.nl/en-gb}{CBS}) in the Hague.

\subsection{Prerequisites}

\begin{itemize}
  \item Attendees should bring their own laptop with (64-bit) \href{https://www.r-project.org/}{R}, and preferably also \href{https://www.rstudio.com/}{RStudio}, installed.
  \item Shortly before the training session we will publish a list of additional packages (e.g. \textbf{sf}, \textbf{mapview} and \textbf{tmap}) to be installed - please keep an eye on our \href{https://github.com/TWIAV/Spatial_Analysis_in_R_with_Open_Geodata}{GitHub repository}.
  \item No specific prior experience (with R) is required for this introductory session, though some basic experience in one or more of the following fields is certainly helpful: Data Science, Programming/Software Development and/or GIS.
\end{itemize}

\end{multicols}

[^1]: https://www.linkedin.com/in/ejhpolle/
[^2]: https://www.linkedin.com/in/willytadema/

##Course material available on GitHub

The URL of this repository: [https://github.com/TWIAV/Spatial_Analysis_in_R_with_Open_Geodata](https://github.com/TWIAV/Spatial_Analysis_in_R_with_Open_Geodata)

\newpage
\newpage
\pdfbookmark{\contentsname}{toc}
\hypersetup{linkcolor=black}
\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}
\tableofcontents
\hypersetup{linkcolor=blue}
\newpage

# Managing Geospatial Vector Data in R {-}  

# The package `sf` (Simple Features for R) \label{simple_features}

To manage spatial data in R you will use the library `sf`, a relativle new addition to the R universe. The package was [released on CRAN in January 2017](https://www.r-consortium.org/blog/2017/01/03/simple-features-now-on-cran).

This package provides support for simple features, which is a standardized way to encode spatial vector data.

`sf` links directly to three important geospatial libraries, to unlock their power for use in R:

* GDAL for reading and writing data
* GEOS for geometrical operations
* Proj.4 for projection conversions and datum transformations.

**The package `sf` on CRAN:**  
[https://cran.r-project.org/web/packages/sf/index.html](https://cran.r-project.org/web/packages/sf/index.html)


If the package is not yet installed, you can install it with the following command:

```{r install_sf, eval = FALSE}
install.packages("sf")
```

To be able to manage your spatial data you will first have to load the package `sf`:

```{r library_sf}
library(sf)
```

\tcbset{coltitle=black, colbacktitle=white, colframe=gray!75!black,colback=white,nobeforeafter}
\begin{tcolorbox}[enlarge by=5mm, hyphenationfix, title=The real geospatial powers behind sf]
\begin{itemize}
\item GDAL: the \textbf{Geospatial Data Abstraction Library} is a translator library for raster and vector geospatial data formats. Website: \url{http://www.gdal.org/}
\item GEOS: the \textbf{Geometry Engine, Open Source} contains the complete functionality of the OpenGIS Simple Features for SQL spatial predicate functions and spatial operators. Website: \url{https://trac.osgeo.org/geos}
\item Proj.4: \textbf{PROJ} is a generic coordinate transformation software, that transforms coordinates from one coordinate reference system (CRS) to another. This includes cartographic projections as well as geodetic transformations. Website: \url{http://proj4.org/}
\end{itemize}
\end{tcolorbox}

# A first exercise

```{r}
ap <- "Lelystad Airport"
cd <- "LEY"
class(cd)
lat <- 52.460278
lon <- 5.527222
class(lon)
airport <- data.frame(ap, cd, lat, lon, stringsAsFactors = FALSE)
NL_Airports <- read.csv("http://www.twiav.nl/files/NL_Airports.csv", stringsAsFactors = FALSE)

print(NL_Airports)

```
```{r, eval = FALSE}
NL_Airports <- rbind(NL_Airports, airport) # This will give an error
```
```{r}
names(airport) <- names(NL_Airports)

NL_Airports <- rbind(NL_Airports, airport)
print(NL_Airports)
class(NL_Airports)

library(sf)

NL_Airports <- st_as_sf(NL_Airports, coords = c("longitude","latitude"), crs = 4326)

class(NL_Airports)

plot(st_geometry(NL_Airports), pch = 17)

```

\newpage

# Interactive Viewing of Spatial Data in R

Until now you have seen some static maps plotted o the **Plots** pane. But as a real Data Scientist you also want to be able to explore your data on an interactive map. Until a few years ago this would have meant switching back and forth between a desktop GIS and R. But in recent years some new packages have been developed to enable interactive map viewing.

In this chapter we will look at some of these.

## The package `mapview`

**The package `mapview` on CRAN:**  
[https://cran.r-project.org/web/packages/mapview/index.html](https://cran.r-project.org/web/packages/mapview/index.html)

If the package is not yet installed, you can install it with the following command:

```{r install_mv, eval = FALSE}
install.packages("mapview")
```

To be able to view your spatial data interactively you will first have to load the package `mapview`:

```{r library_mv}
library(mapview)
```


\newpage

# Accessing Geospatial Vector Data over the Internet {-}

# Downloadable shapefiles

\begin{multicols}{2}

In this chapter we will learn how to download, to unzip and to load shapefiles \textbf{using R}. There will be no need to use your web browser, your file explorer or a zip utility - the whole process can be completed using just a few lines of R code.

The shapefile format is a well-known and still rather popular geospatial vector data format for Geographic Information System (GIS) software. It spatially describes vector features - points, lines, and polygons - with attribute data attached. The shapfile is a 'classic' GIS file format in the sense that it stores geometry and attribute data in separate files (in this chapter we will discover that a single shapefile in reality consits of multiple files) as opposed to more modern spatial database or file formats, where geometry and attributes are stored together in a single table or file.

\includegraphics{Images/cbs.png}

The shapefile format has been developed by \href{https://www.esri.com/}{Esri} and over the years has become a \textit{de facto} standard for data interoperability among Esri and other GIS software products.

It is not uncommon for public organizations - including national statistical institutes - to distribute geographic information in this shapefile format. So, you will find shapefiles on the \href{https://www.cbs.nl/nl-nl/dossier/nederland-regionaal/geografische-data}{page with geographic data of the Dutch Office for National Statistics (CBS)} and also on the \href{http://data.statistik.gv.at/web/catalog.jsp}{STATISTIK AUSTRIA open.data Portal}.

\includegraphics{Images/logo_statistik.png}

\end{multicols}

## Download and unzip the shapefile

```{r eval=FALSE}
# Set the working directory
setwd("C:/uRos2018")
# Store the URL to the file to download in a variable
URL2zip <- "http://data.statistik.gv.at/data/OGDEXT_GEM_1_STATISTIK_AUSTRIA_20180101.zip"
print(URL2zip)
# Extract the filename from this URL
zip_file <- file.path(basename(URL2zip))
print(zip_file)
# Create a subfolder in your working directory to store the data
dir.create("./Data", showWarnings = FALSE)
# store the path to the current working directory in a variable
workdir <- getwd()
# switch to the data folder you just created
setwd("./Data")
# Download the file
download.file(URL2zip, destfile = zip_file, mode = "wb")
# unzip the file
unzip(zip_file)
# after unzipping you can delete (i.e. unlink) the file
unlink(zip_file)
# Return to the original working directory
setwd(workdir)
# remove variables you do not longer need
rm(URL2zip,zip_file,workdir)
```

```{r echo=FALSE}
setwd("C:/uRos2018")
URL2zip <- "http://data.statistik.gv.at/data/OGDEXT_GEM_1_STATISTIK_AUSTRIA_20180101.zip"
zip_file <- file.path(basename(URL2zip))
dir.create("C:/uRos2018/Data", showWarnings = FALSE)
setwd("C:/uRos2018/Data")
download.file(URL2zip, destfile = zip_file, mode = "wb")
unzip(zip_file)
unlink(zip_file)
setwd("C:/uRos2018")
```

## Load the shapefile


```{r eval=FALSE}
library(sf)
library(tmap)
AUSTRIA_GEM_20180101 <- st_read("./Data/STATISTIK_AUSTRIA_GEM_20180101.shp")
```

```{r echo=FALSE}
library(sf)
library(tmap)
AUSTRIA_GEM_20180101 <- st_read("C:/uRos2018/Data/STATISTIK_AUSTRIA_GEM_20180101.shp")
```

```{r eval=FALSE}
qtm(AUSTRIA_GEM_20180101)
```

```{r echo=FALSE}
qtm(AUSTRIA_GEM_20180101)
```



\newpage

# OGC Web Feature Service (WFS) \label{chapWFS}

## Introduction

\begin{multicols}{2}

In this chapter we will learn how \textbf{to use R as a client to access data using a Web Feature Service (WFS)}. WFS is a Data Access Standard which is defined and maintained by the Open Geospatial Consortium (OGC). The WFS Interface Standard defines a set of interfaces for accessing geographic information over the Internet. It offers the means to retrieve geographic features and their properties through a highly configurable interface and in a manner independent of the underlying data stores they publish.

The standard is used - both in the public and private sector and in the academic world - to publish vector geospatial datasets in a way that makes it easy for receiving organisations to conduct analysis on the data supplied.

In a short chapter like this it will not be possible to cover all ins and outs of the WFS Interface Standard. The main goal here is to get you up and running and to whetten your appetite for more. It might all look a bit technical and intimidating at first, but as soon as you have the syntax of your request right, you will be able to retrieve valuable spatial data in the blink of an eye.

\end{multicols}

## WFS Outputformat: GML vs. GeoJSON \label{gmlGEOJSON}

By default, a WFS returns data in Geography Markup Language (GML) which is written as eXtensible Markup Language (XML). However, many WFS services also offer the option to request the ouput in GeoJSON, a geospatial data interchange format based on JavaScript Object Notation (JSON).

By it's very nature, GML data is difficult to process, because - as with most XML based grammars - there are two parts to the grammar: the schema that describes the document and the instance document that contains the actual data.

On the contrary, the GeoJSON standard clearly defines several types of JSON objects and the manner in which they are combined to represent data about geographic features, their properties, and their spatial extents.

In general **GDAL**, the translator library behind the `sf` functions `st_read()` and `st_write` (see chapter \ref{simple_features}), gives better results with GeoJSON as opposed to GML.

So, in the exercises in this manual, when accessing a WFS service o retrieve data, we will always add the parameter `outputFormat=application/json`.

## Access a WFS service: `request=GetCapabilities` \label{GCnl}

In general, organisations publishing data using WFS, will provide you with a URL to their WFS server which also contains a `GetCapabilities` reguest. Once you know the **capabilities** of the service (i.e. once you know what is on offer) you can start building your own request to the server.

In the exercises below we will use data on the municipal division in the Netherlands. These data are offered by the host of this conference, the Dutch statistical office, through [Publieke Dienstverlening op de Kaart](https://www.pdok.nl/) (PDOK) and the [Nationaal Georegister](http://www.nationaalgeoregister.nl/) (NGR).

Some background information on the dataset used, can be found here: [Dataset: CBS Gebiedsindelingen](https://www.pdok.nl/introductie?articleid=1951759).

The actual URL with the `GetCapabilities` reguest is:  
[https://geodata.nationaalgeoregister.nl/cbsgebiedsindelingen/wfs?request=GetCapabilities](https://geodata.nationaalgeoregister.nl/cbsgebiedsindelingen/wfs?request=GetCapabilities)

When you click this link the server response will be shown in your browser in XML format.

We are not going to study this XML response line-by-line. Not now. But please leave the web page open in your browser for later reference.

## Retrieve data from a WFS service: `request=GetFeature` \label{GetFeaturePar}

### `request=GetFeature` - an example from the Netherlands \label{GFnl}

A WFS server responding to a *GetFeature* request returns a collection of geographic feature instances filtered according to a criteria set by the requesting client.

We will start with a simple request to download a full feature collection without any constraints to filter the content by. The GetFeature request queries the server with a set of parameters, which are concatenated to the URL with an *ampersand* (&).

In the script below we use the `httr` package. This allows us to store the different parameters of our request in a list, only to build the full URL at the end. We do so for readability reasons and to allow for easy modification of our request at a later stage if necessary. And the function `build_url()` will return a properly encoded URL.

A WFS service can offer one or more feature collections, see the `<FeatureTypeList>` section in the XML response to the `GetCapalities` request. The service we are accessing here offers quite some feature collections, i.e. multiple regional divisions for the years 1995 up to the current year.

What we are intersted in here, is the municipal division for the year 2017. After some browsing through the XML response, we have found a `<FeatureType>` with the `<Name>` **cbsgebiedsindelingen:cbs_gemeente_2017_gegeneraliseerd**. And that's the value we are giving to the `typename` parameter. (This `typenames` parameter determines the collection of feature instances to return.)

Aslso, do not forget to add a parameter to ask for output in GeoJSON format (as discussed in paragraph \ref{gmlGEOJSON}).

This is the script to populate the full request:

```{r}
# NL: Example with Dutch data
library(sf)
library(tmap)
library(httr)

url <- parse_url("geodata.nationaalgeoregister.nl/cbsgebiedsindelingen/wfs?")
url$scheme <- "https"
url$query<- list(service = "WFS",
                 version = "2.0.0",
                 request = "GetFeature",
                 typename = "cbsgebiedsindelingen:cbs_gemeente_2017_gegeneraliseerd",
                 outputFormat = "application/json")
request <- build_url(url)
print(request)
```

The variable `request` will now contain this [link](https:///geodata.nationaalgeoregister.nl/cbsgebiedsindelingen/wfs?service=WFS&version=2.0.0&request=GetFeature&typename=cbsgebiedsindelingen%3Acbs_gemeente_2017_gegeneraliseerd&outputFormat=application%2Fjson). (When you click this link the server response will be shown in your browser in GeoJSON format.)

Now we want to feed this response directly into R, like this:

```{r}
NL_Municipalities2017 <- st_read(request)
```

\newpage
Have a look at the result:

```{r}

qtm(NL_Municipalities2017)

head(NL_Municipalities2017)

```
\newpage

### `request=GetFeature` - an example from Finland


In this paragraph we will retrieve data from [Tilastokeskus (Statistics Finland)](http://www.stat.fi/). In the english section of their website we found a nice dataset: [Population by municipality-based units](http://www.stat.fi/org/avoindata/paikkatietoaineistot/vaesto_tilastointialueittain_en.html).


\begin{multicols}{2}
And from this map it is especially the layer \textbf{Population 2017 by municipalities 2018 (kunta\_vaki2017)} we would like to investigate.

We will follow the same steps as in the Dutch example above. For an explanation of the steps taken, please refer to paragraph \ref{GCnl} and \ref{GFnl}.

\includegraphics{Images/tklogo_fi.png}

\end{multicols}

The URL with `GetCapabilities` request is:  
[http://geo.stat.fi/geoserver/vaestoalue/wfs?request=GetCapabilities](http://geo.stat.fi/geoserver/vaestoalue/wfs?request=GetCapabilities)

In this XML response - in the `<FeatureTypeList>` section - we have found a `<FeatureType>` with the `<Name>` **vaestoalue:kunta_vaki2017**. That's the value we are giving to the `typename` parameter.

The script to build the full URL is similar to the one before - the only parameters we have modified are the url and the typename:

```{r}
# FI: Example with Finnish data
library(sf)
library(tmap)
library(httr)

url <- parse_url("geo.stat.fi/geoserver/vaestoalue/wfs?")
url$scheme <- "https"
url$query<- list(service = "WFS",
                 version = "2.0.0",
                 request = "GetFeature",
                 typename = "vaestoalue:kunta_vaki2017",
                 outputFormat = "application/json")
request <- build_url(url)
print(request)

```

The variable `request` will now contain this [link](https:///geo.stat.fi/geoserver/vaestoalue/wfs?service=WFS&version=2.0.0&request=GetFeature&typename=vaestoalue%3Akunta_vaki2017&outputFormat=application%2Fjson). (When you click this link the server response will be shown in your browser in GeoJSON format.)

Now we want to feed this response directly into R, like this:

```{r}
FI_Municipalities2018_Pop2017 <- st_read(request)
```
\newpage

Have a look at the result:

```{r}
qtm(FI_Municipalities2018_Pop2017)
```

Optionally, you can have a look at the attribute data in the **Data Viewer**: `View(FI_Municipalities2018_Pop2017)`

\begin{multicols}{2}

With some basic knowledge of the Finnish language you should now be able to calculate that Finland had more ore less 5.5 million inhabitants in 2017 - of which more or less 50 percent are males, and the other half females:

\tcbset{coltitle=black, colbacktitle=white, colframe=gray!75!black,colback=white,nobeforeafter}
\begin{tcolorbox}[enlarge by=5mm, hyphenationfix, title=Finnish for Data Scientists: some useful words]
\begin{itemize}
\item \textbf{Miehet} = Men
\item \textbf{Naiset} = Women
\item \textbf{Nimi} = Name
\item \textbf{Vaesto} = Population
\end{itemize}
\end{tcolorbox}

\end{multicols}

```{r}
sum(FI_Municipalities2018_Pop2017$vaesto)
sum(FI_Municipalities2018_Pop2017$miehet)
sum(FI_Municipalities2018_Pop2017$naiset)
```

\newpage

## Get a description of a dataset: `request=DescribeFeatureType` \label{parDescFeatType}

In the previous exercises we immediately executed `GetFeature` requests to WFS services - mainly because the trainer told us to do so - without actually knowing anything about these datasets.

To get a description of the dataset, you can execute a `DescribeFeatureType` request first. This returns a description - in XML format - of the structure, including properties, of the feature type specified in the request.

For the Dutch municipalities dataset this request would look like this:
[https://geodata.nationaalgeoregister.nl/cbsgebiedsindelingen/wfs?service=WFS&version=2.0.0&request=DescribeFeatureType&typename=cbsgebiedsindelingen:cbs_gemeente_2017_gegeneraliseerd](https://geodata.nationaalgeoregister.nl/cbsgebiedsindelingen/wfs?service=WFS&version=2.0.0&request=DescribeFeatureType&typename=cbsgebiedsindelingen:cbs_gemeente_2017_gegeneraliseerd)

And for the Finnish dataset like this:
[http://geo.stat.fi/geoserver/vaestoalue/wfs?service=WFS&version=2.0.0&request=DescribeFeatureType&typename=vaestoalue:kunta_vaki2017](http://geo.stat.fi/geoserver/vaestoalue/wfs?service=WFS&version=2.0.0&request=DescribeFeatureType&typename=vaestoalue:kunta_vaki2017)

## Additional parameters to the `GetFeature` request

Additional parameters can be added to a `GetFeature` request to further filter or convert the response from the WFS.

To include additional parameters to a request, simply add an *ampersand* (&) at the end of the URL, then add the name of the parameter, an equal sign (=) and the value to assign to the parameter. Of course we will not do this manually; we will use the `httr` package to build this URL with additional parameters for us.

Below we will discuss a few of the parameters available.

### Limit the number of records returned: the `count` parameter

To have a look at the structure of a dataset - before retrieving the full dataset - you can choose to limit the number of records returned with the `count` parameter.

The `GetFeature` request below limits the number of Finnish municipalities returned to only 5:

```{r}
# FI: Example with Finnish data
library(httr)

url <- parse_url("geo.stat.fi/geoserver/vaestoalue/wfs?")
url$scheme <- "https"
url$query<- list(service = "WFS",
                 version = "2.0.0",
                 request = "GetFeature",
                 typename = "vaestoalue:kunta_vaki2017",
                 count = 5,
                 outputFormat = "application/json")
request <- build_url(url)
print(request)

```
The variable `reques` will now contain this [link](https:///geo.stat.fi/geoserver/vaestoalue/wfs?service=WFS&version=2.0.0&request=GetFeature&typename=vaestoalue%3Akunta_vaki2017&count=5&outputFormat=application%2Fjson). (When you click this link the server response will be shown in your browser in GeoJSON format.)

\newpage

### Limit the number of columns returned: the `PropetyName` parameter

To restrict a `GetFeature` request by attribute rather than feature, use the `PropertyName` parameter. You can specify a single attribute, or multiple attributes separated by commas.

The `GetFeature` request below only returns the geometry and the columns *nimi* (Name) and *vaesto* (total population) for the Finnish municipalities:

```{r}
# FI: Example with Finnish data
library(httr)

url <- parse_url("geo.stat.fi/geoserver/vaestoalue/wfs?")
url$scheme <- "https"
url$query<- list(service = "WFS",
                 version = "2.0.0",
                 request = "GetFeature",
                 typename = "vaestoalue:kunta_vaki2017",
                 propertyname = "geom,nimi,vaesto",
                 outputFormat = "application/json")
request <- build_url(url)
print(request)

```
The variable `request` will now contain this [link](https:///geo.stat.fi/geoserver/vaestoalue/wfs?service=WFS&version=2.0.0&request=GetFeature&typename=vaestoalue%3Akunta_vaki2017&propertyname=geom%2Cnimi%2Cvaesto&outputFormat=application%2Fjson). (When you click this link the server response will be shown in your browser in GeoJSON format.)

\newpage

## Further reading

The OGC offers an official tutorial module - [OGC E-learning](http://cite.opengeospatial.org/pub/cite/files/edu/index.html) - covering it's activities and the several standards it maintains. The [specific chapter on WFS](http://cite.opengeospatial.org/pub/cite/files/edu/wfs/text/basic-index.html) can be found [here](http://cite.opengeospatial.org/pub/cite/files/edu/wfs/text/basic-index.html).

\newpage

\begin{figure}[H]
\centering
\caption{On the overview page metadata about the \textbf{Feature Layer} \textit{USA States (Generalized)} is presented}
\vspace{5pt}
\includegraphics{Images/Feature_Layer_USA_States_Metadata.png}
\label{USA_States_AGOL_Metadata}
\end{figure}
\begin{figure}[H]
\centering
\caption{Here the \textbf{Feature Layer} \textit{USA States (Generalized)} is shown in the \textbf{ArcGIS Online Map Viewer}}
\vspace{5pt}
\includegraphics{Images/Feature_Layer_USA_States_Map_Viewer.png}
\label{USA_States_AGOL_MapViewer}
\end{figure}

\newpage

# ArcGIS REST Service

## Introduction

\begin{multicols}{2}

In this chapter we will learn how \textbf{to use R as a client to access data using an ArcGIS REST Service}. We will be accessing ArcGIS Server to retrieve Feature Layers using the \href{https://developers.arcgis.com/rest/}{ArcGIS REST API}. This API is part of ArcGIS Online,  the "complete SaaS mapping platform" by the American GIS company \href{https://www.esri.com/en-us/home}{Esri}. And as part of this platform Esri has launched the \href{https://livingatlas.arcgis.com/en/}{ArcGIS Living Atlas of the World}\footnote{Some background information on the Living Atlas of the World can be found in this \href{http://www.esri.com/esri-news/arcuser/summer-2015/welcome-to-the-living-atlas-of-the-world}{article}, where Esri also invites YOU to \textit{"Become a user and a contibutor"}.}

Some datasets in this Living Atlas are Open Data. Some, but by no means all, as many datasets are only accessible via an ArcGIS Online organizational account. But in cases where the source data is already Open Data, Esi publishes the data under the same conditions.

\includegraphics{Images/living-atlas-logo-size-4.png}

\end{multicols}

## Exploring data in the ArcGIS Living Atlas of the World

Afer some browsing through the content of the Living Atlas we have found a nice (and open) dataset for this exercise: the **Feature Layer** *USA States (Generalized)*. An overview page with metadata for the dataset we have chosen can be found via this [link](https://www.arcgis.com/home/item.html?id=99fd67933e754a1181cc755146be21ca#overview) (see Figure \ref{USA_States_AGOL_Metadata}). 

Before actually importing the data into R, you can expore the dataset - both the geometry and the attribute data - in the [ArcGIS Online Map Viewer](https://www.arcgis.com/home/webmap/viewer.html?useExisting=1&layers=99fd67933e754a1181cc755146be21ca) (see Figure \ref{USA_States_AGOL_MapViewer}).

## Query the Feature Service

On the overview page we have found the Service URL pointing to the layer **USA_States_Generalized** in the the Services Directory (see Figure \ref{USA_States_AG_REST_Services_Dir}): 

[https://services.arcgis.com/P3ePLMYs2RVChkJx/arcgis/rest/services/USA_States_Generalized/FeatureServer/0](https://services.arcgis.com/P3ePLMYs2RVChkJx/arcgis/rest/services/USA_States_Generalized/FeatureServer/0)

One of the **Supported Operations** for this layer is **Query**. The *Query* page (see Figure \ref{USA_States_AG_REST_Services_Dir_Query}) offers an interface to construct the query: 

[https://services.arcgis.com/P3ePLMYs2RVChkJx/arcgis/rest/services/USA_States_Generalized/FeatureServer/0/query](https://services.arcgis.com/P3ePLMYs2RVChkJx/arcgis/rest/services/USA_States_Generalized/FeatureServer/0/query)

Let's try to build a request to retrieve the full dataset:

* The first parameter is `where`. It is obligatory and cannot be ommited. If there is no *where-clause* (i.e. if you want to extract the full dataset) you have to populate this parameter with the value `1=1` (which is - of course - always true...)
* To get all the attribute columns you to give the parameter `outFields` the value `*`
* To retrieve the spatial data the parameter `returnGeomatry` should be set to `true`
* And the outputformat - `f` - is set to `geojson`


\newpage

\begin{figure}[H]
\centering
\caption{On this page the \textbf{Feature Layer} \textit{USA\_States\_Generalized} is presented in the \textbf{ArcGIS REST Services Directory}}
\vspace{5pt}
\includegraphics{Images/ArcGIS_REST_Services_Directory_USA_States_FeatureServer.png}
\label{USA_States_AG_REST_Services_Dir}
\end{figure}
\begin{figure}[H]
\centering
\caption{On this page you can enter parameters to query the \textbf{Feature Layer} \textit{USA\_States\_Generalized}}
\vspace{5pt}
\includegraphics{Images/ArcGIS_REST_Services_Directory_USA_States_FeatureServer_query.png}
\label{USA_States_AG_REST_Services_Dir_Query}
\end{figure}


\newpage

This is the script to populate the full request:

```{r}
# USA: An example with American data
library(sf)
library(tmap)
library(httr)

url <- parse_url(paste0("services.arcgis.com/P3ePLMYs2RVChkJx/arcgis/rest/services/","USA_States_Generalized/FeatureServer/0/query?"))
url$scheme <- "https"
url$query<- list(where = "1=1",
                 outFields = "*",
                 returnGeometry = "true",
                 f = "geojson")
request <- build_url(url)
print(request)
```

The variable `request` will now contain this [link](https:///services.arcgis.com/P3ePLMYs2RVChkJx/arcgis/rest/services/USA_States_Generalized/FeatureServer/0/query?where=1%3D1&outFields=%2A&returnGeometry=true&f=geojson). (When you click this link the server response will be shown in your browser in GeoJSON format.)

Now we want to feed this response directly into R, like this:

```{r}
USA_States_2017 <- st_read(request)
```

\newpage

Have a look at the result:

```{r}
qtm(USA_States_2017)
```



\tcbset{coltitle=black, colbacktitle=white, colframe=gray!75!black,colback=white,nobeforeafter}
\begin{tcolorbox}[enlarge by=5mm, hyphenationfix, title=Anchorage]
"Hey Chel you know it's kinda funny\\
 Texas always seems so big\\
 But you know you're in the largest State in the Union\\
 When you're anchored down in Anchorage"\\
\\ 
 \textbf{Michelle Shocked} - Short Sharp Shocked - 1988
\end{tcolorbox}

\newpage

## Additional parameters to the `query` request

### Filter the records returned: specify the `where`-clause

To filter records you can specify a `where`-clause.

The `query` request below only returns those States which have more than 10 million inhabitants:

```{r}
# USA: An example with American data
library(httr)

url <- parse_url(paste0("services.arcgis.com/P3ePLMYs2RVChkJx/arcgis/rest/services/","USA_States_Generalized/FeatureServer/0/query?"))
url$scheme <- "https"
url$query<- list(where = "POPULATION>10000000",
                 outFields = "STATE_NAME,POPULATION",
                 returnGeometry = "true",
                 f = "geojson")
request <- build_url(url)
print(request)
```

The variable `request` will now contain this [link](https:///services.arcgis.com/P3ePLMYs2RVChkJx/arcgis/rest/services/USA_States_Generalized/FeatureServer/0/query?where=POPULATION%3E10000000&outFields=STATE_NAME%2CPOPULATION&returnGeometry=true&f=geojson). (When you click this link the server response will be shown in your browser in GeoJSON format.)


### Limit the number of columns returned: the `outFields` parameter

If you do not need all attribute columns of a dataset in your analysis, you can limit the number of columns returned by specifyng the `outFields` parameter. You can specify a single attribute, or multiple attributes separated by commas.

The `query` request below only returns the geometry and the columns STATE_NAME and POPULATION for the United States:

```{r}
# USA: An example with American data
library(httr)

url <- parse_url(paste0("services.arcgis.com/P3ePLMYs2RVChkJx/arcgis/rest/services/","USA_States_Generalized/FeatureServer/0/query?"))
url$scheme <- "https"
url$query<- list(where = "1=1",
                 outFields = "STATE_NAME,POPULATION",
                 returnGeometry = "true",
                 f = "geojson")
request <- build_url(url)
print(request)
```

The variable `request` will now contain this [link](https:///services.arcgis.com/P3ePLMYs2RVChkJx/arcgis/rest/services/USA_States_Generalized/FeatureServer/0/query?where=1%3D1&outFields=STATE_NAME%2CPOPULATION&returnGeometry=true&f=geojson). (When you click this link the server response will be shown in your browser in GeoJSON format.)

\newpage

# Statistics Netherlands (CBS) StatLine databank as open data

\begin{multicols}{2}

All tables in the \href{https://opendata.cbs.nl/statline/portal.html?_la=en&_catalog=CBS}{Statistics Netherlands (CBS) StatLine databank} are available as open data. Since 2014 this databank has an open data web API based on the OData protocol (\url{https://www.odata.org/}).

Using web services, data can be retrieved, filtered and combined. In this way, Statistics Netherlands aims to promote the widespread use of its statistical data.

In this chapter we will load Dutch statistical data directly into R, using the package `cbsodataR`, the Statistics Netherlands (CBS) Open Data API Client for R.

\includegraphics{Images/cbs.png}

\end{multicols}

## the package `cbsodataR`

The package `cbsodaataR` can be found on CRAN: [https://cran.r-project.org/package=cbsodataR](https://cran.r-project.org/package=cbsodataR)

The table of contents can be retrieved with the fucnction `cbs_get_toc()`. As we browse through the table of content we do see a total of 4418 entries. For most datasets all the metadata is in Dutch, but for some of them this information is also available in English.

When we split the TOC by language we do see that currently 698 datasets are available with metadata in English. These 'English' datasets are actually copies of their Dutch equivalents. (Maybe overtime all tables will be available with a description in English?)

This is a wealth of information, and all these datasets can be directly loaded into R. In the next paragraph we will do some exercises with one particular table.

```{r}
library(cbsodataR)

toc <- cbs_get_toc()
nrow(toc)
toc_nl <- cbs_get_toc(Language="nl")
nrow(toc_nl)
toc_en <- cbs_get_toc(Language="en")
nrow(toc_en)

```

\newpage

\tcbset{coltitle=black, colbacktitle=white, colframe=gray!75!black,colback=white,nobeforeafter}
\begin{tcolorbox}[enlarge by=5mm, hyphenationfix, title=NUTS - Nomenclature des Unités Territoriales Statistiques]
\href{http://ec.europa.eu/eurostat/web/main/home}{Eurostat} uses a set of geospatial classifications, but the heart of these is NUTS:  the \textbf{Nomenclature of Territorial Units for Statistics}.\\
This classification was set up by Eurostat at the beginning of the 1970s. It serves as a single, coherent system for dividing up the EU's territory in order to produce regional statistics for the European Union.\\
\\
Ther are three levels of NUTS regions:
\begin{itemize}
\item{NUTS 1: major socio-economic regions}
\item{NUTS 2: basic regions for the application of regional policies}
\item{NUTS 3: small regions for specific diagnoses}
\end{itemize}

\includegraphics{Images/Eurostat_logo.png}
More information on the NUTS classification can be found here: \url{http://ec.europa.eu/eurostat/web/nuts/background}\\
\\
Eurostat even created a nice video on the topic: \url{https://youtu.be/a4Y-hCQ-Klo}
\end{tcolorbox}

## NUTS regions in the Netherlands: exercises with regional statistical data

### Preparing the data

The table we have chosen for the exercises in this paragraph is called 'Regionale kerncijfers Nederland', i.e. Regeional statistical data about the Netherlands.
The identifier of this table is **70072ned**. It is a huge table containing data at 5 regional levels - from the country as a whole down to the municipal level - from 1995 up to the current year.

The table can be retrieved with the fucnction `cbs_get_data()`:

```{r eval=FALSE}
NL_Regional_Statistics2017 <- cbs_get_data('70072ned')
```

As we do not need the full table, we will limit the amount of data loaded.

Firstly, we are only interested in the year 2017. We want to analyse the total population by region for that particular year.

So, we come up with the following statement (we will explain the selection of columns below):

```{r, message = FALSE, warning = FALSE}
library(dplyr)
library(data.table)
library(stringr)
```

```{r}
NL_Regional_Statistics2017 <- cbs_get_data('70072ned', Perioden = "2017JJ00") %>% select(RegioS,Perioden,TotaleBevolking_1,Code_291,Naam_292,Code_293,Naam_294)
```

The first two columns - `RegioS` and `Perioden` - are categorical columns, i.e. they contain codes. The labels for these columns can be added with the function `cbs_add_label_columns()`:

```{r}
NL_Regional_Statistics2017 <- NL_Regional_Statistics2017 %>% cbs_add_label_columns()
```

We will now rename the columns of our table for further use in the exercise:

```{r}
names(NL_Regional_Statistics2017) <- c("Regional_level","Regional_level_label","Year","Year_label","Total_population","Region_code","Region_name","Province_code","Province_name")
```
Each column has a label. To avoid issues later on in this exercise, we will remove these labels now:

```{r}
for (i in names(NL_Regional_Statistics2017)) {
  attr(NL_Regional_Statistics2017[[deparse(as.name(i))]], "label") <- NULL
}
```

Let's have a first look at the table:

```{r}
head(NL_Regional_Statistics2017)

```

In the first row we can see the total number of inhabitants in the Netherlands on January 1st, 2017, which is: *17,081,507*.

And wait, we notice something else: some columns seem to have a fixed width. For example, the columns `Regional_level` and  `Region_name`:

```{r}
paste(NL_Regional_Statistics2017$Regional_level[1])
paste(NL_Regional_Statistics2017$Region_name[6])
```
```{r}
my_string <- paste(NL_Regional_Statistics2017$Region_name[6])
nchar(my_string)
```
This is weird, isn't it? The string 'Noord-Nederland' - which is only 15 charaters in length - is filled out with trailing spaces to have a length of 50... This can't be good, can it? We want our strings to behave like strings with their proper length, not carrying around a trail of whitespaces.

Let's fix this issue with the function `trimws()` for the columns concerned:

```{r}
NL_Regional_Statistics2017$Regional_level <- as.factor(trimws(NL_Regional_Statistics2017$Regional_level))
NL_Regional_Statistics2017$Region_code <- as.factor(trimws(NL_Regional_Statistics2017$Region_code))
NL_Regional_Statistics2017$Region_name <- as.factor(trimws(NL_Regional_Statistics2017$Region_name))
NL_Regional_Statistics2017$Province_code <- as.factor(trimws(NL_Regional_Statistics2017$Province_code))
NL_Regional_Statistics2017$Province_name <- as.factor(trimws(NL_Regional_Statistics2017$Province_name))
```

```{r}
head(NL_Regional_Statistics2017)

```

This looks much better!

### Extracting NUTS 1 and NUTS 2 regions

Now that we have prepared our data, we can extract the data about NUTS 1 and NUTs 2 respectively

```{r}

NL_Regions2017 <- NL_Regional_Statistics2017 %>% filter(Regional_level %like% "LD")
NL_Provinces2017 <- NL_Regional_Statistics2017 %>% filter(Regional_level %like% "PV")
```

```{r}
NL_Provinces2017
```

We have noticed that the province names in the column `Regional_level_label` all have the suffix *(PV)*. Let's get rid of it:

```{r}
NL_Provinces2017$Regional_level_label <- str_replace(NL_Provinces2017$Regional_level_label," \\(PV\\)", "")

```

Likewise, the region names in the column `Regional_level_label` all have the suffix *(LD)*. We will also remove that:


````{r}
NL_Regions2017$Regional_level_label <- str_replace(NL_Regions2017$Regional_level_label," \\(LD\\)", "")
NL_Regions2017
```

\newpage

### `barplot()`

Let's investigate the spread of the Dutch population over the different regions by creating a barplot.

The most basic call to the `barplot()` function, is just to provide a column from a dataset and leave all the defaults:

```{r exbplot1, eval=FALSE}
barplot(NL_Provinces2017$Total_population) # Try this yourself - result not printed in this manual
```

This returns a very basic plot, with no labels and no title, so not very useful.

Use `?barplot()` to see what arguments you can use. After some trial and error you might come to a statement like this:

```{r exbplot2}
barplot(NL_Provinces2017$Total_population/1000000, names = NL_Provinces2017$Regional_level_label, las = 2, cex.axis = .6, cex.names = .6, ylab = "Inhabitants (* 1.000.000)", cex.lab = .8, space = 0, col = "lightblue", main = "Number of Inhabitants by Province - The Netherlands - 2017", cex.main = .8)
```

Not bad at all, for a first attempt. Please note: the provinces are not presented in alphabetical order, but in their  *natural* order, from Groningen (PV20) in the North to Limburg (PV31) in the South.

The provinces at the NUTS 2 level are grouped into regions ('Landsdelen') at the NUTS 1 level. We do know for each province to which region it belongs. Wouldn't it be nice to reflect this division in the plot?

So, In the next plot we will color the bars by region - North, East, West, South - using the `col` argument.

We will need 4 different colors for this plot. In the statement below we use the `palette()` function to manipulate the color palette which is used when a `col=` has a numeric index. Using the `c()` function you create a vector with 4 distinct colors, which is passed as an argument into `palette()`:

```{r}
palette(c("royalblue3","firebrick3","darkolivegreen4","goldenrod1"))
```


And now we can create te barplot like this - with the arguments for the legend provided as a `list`:

```{r}
barplot(NL_Provinces2017$Total_population/1000000, names = NL_Provinces2017$Regional_level_label, las = 2, cex.axis = .6, cex.names = .6, ylab = "Inhabitants ( * 1,000,000)", col = NL_Provinces2017$Region_name, border = "grey", main = "Number of Inhabitants by Province - The Netherlands - 2017", cex.main = .8, legend.text = unique(NL_Provinces2017$Region_name), args.legend = list(x = 'topleft', bty = 'n', fill = unique(NL_Provinces2017$Region_name), border = 'grey'))
```

### `pie()`

Based on the plots in the previous sections we might think that almost half the Dutch population lives in the westernmost region.
  
To confirm this hypothesis we will create a pie chart with the population by region.



Create a pie chart:
```{r}
pie(NL_Regions2017$Total_population, labels = NL_Regions2017$Regional_level_label)
```

\newpage

```{r}
NL_Regions2017$Regional_level_label <- as.factor(NL_Regions2017$Regional_level_label)
pct <- round(NL_Regions2017$Total_population/sum(NL_Regions2017$Total_population)*100, 1)
pct <- paste0(pct, "%")
lbls <- paste(NL_Regions2017$Regional_level_label, "\n", pct)
palette(c("royalblue3","firebrick3","darkolivegreen4","goldenrod1"))
pie(NL_Regions2017$Total_population, labels = lbls,
cex = .8, col = NL_Regions2017$Regional_level_label, border = "grey",
main = "Number of Inhabitants by Region - The Netherlands - 2017")
```

```{r echo = FALSE, results = 'hide', message = FALSE}
palette("default")
```


```{r}

NL_Municipalities2017 <- NL_Regional_Statistics2017 %>% filter(Regional_level %like% "GM")
NL_Municipalities2017 <- NL_Municipalities2017 %>% filter(Total_population != "")
```



\newpage

# References {-}

* **Lovelace, Robin, Jakub Nowosad & Jannes Muenchow** (Forthcoming). *Geocomputation with R*. CRC Press. Online version: [https://geocompr.robinlovelace.net/](https://geocompr.robinlovelace.net/)
* **Pebesma, Edzer** (January 3, 2017). *Simple Features Now on CRAN*. Blog. Retreived from: [https://www.r-consortium.org/blog/2017/01/03/simple-features-now-on-cran](https://www.r-consortium.org/blog/2017/01/03/simple-features-now-on-cran)


\newpage

# Appendix A: List of abbreviations used {-}

Abbreviation | Meaning
-------------|----------
API | application programming interface
CRAN | Comprehensive R Archive Network
GIS | Geographic Information System
GML | Geography Markup Language
JSON | JavaScript Object Notation
OGC | Open Geospatial Consortium
REST | Representational State Transfer
SaaS | software as a service
WFS | Web Feature Service
XML | eXtensible Markup Language

\newpage

# Appendix B: Additional exercises {-}

## OGC Web Feature Service (WFS) {-}

For background information on the steps taken in the exercise below, please refer to chapter \ref{chapWFS}

### `request=GetFeature` - another example from the Netherlands {-}

In this additional exercise we will access a WFS service offering information about *bevolkingskernen* (human settlements) in the Netherlands in 2011. More information on this dataset can be found here: [Dataset: CBS Bevolkingskernen](https://www.pdok.nl/introductie?articleid=1951745).

The URL with `GetCapabilities` request is:  
[https://geodata.nationaalgeoregister.nl/bevolkingskernen2011/wfs?request=GetCapabilities](https://geodata.nationaalgeoregister.nl/bevolkingskernen2011/wfs?request=GetCapabilities)

In the `<FeatureTypeList>` section of this XML response we can see that this service only offers one `<FeatureType>`, i.e. one dataset. This dataset has the `<Name>` **bevolkingskernen2011:cbsbevolkingskernen2011**. That's the value we are giving to the `typename` parameter in our `GetFeature` request.


The URL with `DescribeFeatureType` request is:  
[https://geodata.nationaalgeoregister.nl/bevolkingskernen2011/wfs?service=WFS&version=2.0.0&request=DescribeFeatureType&typename=bevolkingskernen2011:cbsbevolkingskernen2011](https://geodata.nationaalgeoregister.nl/bevolkingskernen2011/wfs?service=WFS&version=2.0.0&request=DescribeFeatureType&typename=bevolkingskernen2011:cbsbevolkingskernen2011)

This dataset does contain quite some attribute columns!

This is the script to build the full `GetFeature` request:

```{r}
# NL: Human Settlement Analysis
library(sf)
library(tmap)
library(httr)

url <- parse_url("geodata.nationaalgeoregister.nl/bevolkingskernen2011/wfs?")
url$scheme <- "https"
url$query<- list(service = "WFS",
                 version = "2.0.0",
                 request = "GetFeature",
                 typename = "bevolkingskernen2011:cbsbevolkingskernen2011",
                 outputFormat = "application/json")
request <- build_url(url)
print(request)



```
The variable `request` will now contain this [link](https:///geodata.nationaalgeoregister.nl/bevolkingskernen2011/wfs?service=WFS&version=2.0.0&request=GetFeature&typename=bevolkingskernen2011%3Acbsbevolkingskernen2011&outputFormat=application%2Fjson). (When you click this link the server response will be shown in your browser in GeoJSON format.)

Now we want to feed this response directly into R, like this:

```{r}
NL_Human_Settlements2011 <- st_read(request)
```

\newpage

```{r}
plot(st_geometry(NL_Human_Settlements2011), col = "orange", border = "red")
```

